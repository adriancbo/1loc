{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adriancbo/1loc/blob/master/ultimate_rvc_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmyCzJVyCymN"
      },
      "source": [
        "Colab for [Ultimate RVC](https://github.com/JackismyShephard/ultimate-rvc)\n",
        "\n",
        "This Colab notebook will **help** you if you don’t have a GPU or if your PC isn’t very powerful.\n",
        "\n",
        "Simply click `Runtime` in the top navigation bar and `Run all`. Wait for the output of the final cell to show the public gradio url and click on it.\n",
        "\n",
        "NOTE: If Ultimate RVC is running too slowly with the default sharing method (gradio), consider instead selecting \"ngrok\" as sharing method.\n",
        "This method requires supplying an access token, which you can find on [ngrok](https://ngrok.com/) after creating a personal account.\n",
        "The ngrok link output in the final cell will lead you to a new site which will redirect you to Ultimate RVC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1wl8B6jnzjv",
        "outputId": "d17d45ef-de59-4e8e-bf83-36e9935948ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 57 ms (started: 2025-09-06 21:45:17 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# @title 0: Initialize notebook\n",
        "%pip install ipython-autotime pyngrok\n",
        "%load_ext autotime\n",
        "\n",
        "import codecs\n",
        "import os\n",
        "import time\n",
        "from pathlib import Path\n",
        "from urllib import request\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import clear_output\n",
        "from IPython.display import display as i_display\n",
        "from pyngrok import ngrok\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaokDv1VzpAX",
        "outputId": "14a24314-04c0-43e7-93cb-fd34411e2af1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 1.42 s (started: 2025-09-06 21:45:17 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# @title 1: Clone repository\n",
        "cloneing = codecs.decode(\n",
        "    \"uggcf://tvguho.pbz/WnpxvfzlFurcuneq/hygvzngr-eip.tvg\",\n",
        "    \"rot_13\",\n",
        ")\n",
        "\n",
        "!git clone $cloneing HRVC\n",
        "%cd /content/HRVC\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVGNygIa0F_1",
        "outputId": "9a56d523-2552-474e-afe3-73055f2d463f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 3min 58s (started: 2025-09-06 21:45:19 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# @title 2: Install dependencies\n",
        "\n",
        "light = codecs.decode(\"uggcf://nfgeny.fu/hi/0.6.3/vafgnyy.fu\", \"rot_13\")\n",
        "inits = codecs.decode(\"./fep/hygvzngr_eip/pber/znva.cl\", \"rot_13\")\n",
        "prerelease = \"--prerelease if-necessary-or-explicit\"\n",
        "\n",
        "!apt install -y python3-dev unzip\n",
        "!curl -LsSf $light | sh\n",
        "\n",
        "os.environ[\"URVC_CONSOLE_LOG_LEVEL\"] = \"WARNING\"\n",
        "!uv run -q $prerelease $inits\n",
        "!uv add $prerelease matplotlib-inline==0.1.7\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVGNygIa0F_2",
        "outputId": "ddb99c12-7994-4250-c659-5df899a8186e"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ngrok URL: https://b0f3387eef3f.ngrok-free.app\n",
            "\u001b[2mBytecode compiled \u001b[1m18297 files\u001b[0m \u001b[2min 1.46s\u001b[0m\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2025-09-06T22:14:00+0000 lvl=warn msg=\"failed to open private leg\" id=4b900bfd10bd privaddr=localhost:6969 err=\"dial tcp 127.0.0.1:6969: connect: connection refused\"\n",
            "WARNING:pyngrok.process.ngrok:t=2025-09-06T22:14:01+0000 lvl=warn msg=\"failed to open private leg\" id=9362df2cb451 privaddr=localhost:6969 err=\"dial tcp 127.0.0.1:6969: connect: connection refused\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* Running on local URL:  http://127.0.0.1:6969\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n",
            "100% 53/53 [01:29<00:00,  1.68s/it]\n",
            "\u001b[1m[\u001b[0m~\u001b[1m]\u001b[0m Extracting pitch features\u001b[33m...\u001b[0m\n",
            "100% 841/841 [00:25<00:00, 33.62it/s]\n",
            "\u001b[1m[\u001b[0m~\u001b[1m]\u001b[0m Extracting audio embeddings\u001b[33m...\u001b[0m\n",
            "100% 841/841 [00:15<00:00, 54.33it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/HRVC/src/ultimate_rvc/web/common.py\", line 70, in _wrapped_fn\n",
            "    res = fn(*args, **kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/HRVC/src/ultimate_rvc/core/train/train.py\", line 288, in run_training\n",
            "    pg, pd = _get_pretrained_model(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/HRVC/src/ultimate_rvc/core/train/train.py\", line 99, in _get_pretrained_model\n",
            "    raise IncompatibleVocoderError(vocoder)\n",
            "ultimate_rvc.core.exceptions.IncompatibleVocoderError: The default pretrained model is incompatible with the vocoder RefineGAN.\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/HRVC/.venv/lib/python3.12/site-packages/gradio/queueing.py\", line 625, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/HRVC/.venv/lib/python3.12/site-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/HRVC/.venv/lib/python3.12/site-packages/gradio/blocks.py\", line 2136, in process_api\n",
            "    result = await self.call_function(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/HRVC/.venv/lib/python3.12/site-packages/gradio/blocks.py\", line 1662, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/HRVC/.venv/lib/python3.12/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
            "    return await get_async_backend().run_sync_in_worker_thread(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/HRVC/.venv/lib/python3.12/site-packages/anyio/_backends/_asyncio.py\", line 2476, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/content/HRVC/.venv/lib/python3.12/site-packages/anyio/_backends/_asyncio.py\", line 967, in run\n",
            "    result = context.run(func, *args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/HRVC/.venv/lib/python3.12/site-packages/gradio/utils.py\", line 883, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/HRVC/src/ultimate_rvc/web/common.py\", line 77, in _wrapped_fn\n",
            "    raise gr.Error(str(e)) from e\n",
            "gradio.exceptions.Error: 'The default pretrained model is incompatible with the vocoder RefineGAN.'\n",
            "/content/HRVC/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/content/HRVC/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "krystal | epoch=1 | time=22:29:43 | speed=0:03:20 | best avg-gen-loss=18.744 (epoch 1) | overtrain countdown: g=50,d=100 | avg-gen-loss=18.744 | avg-disc-loss=0.076\n",
            "krystal | epoch=2 | time=22:32:20 | speed=0:02:36 | best avg-gen-loss=15.295 (epoch 2) | overtrain countdown: g=50,d=100 | avg-gen-loss=15.295 | avg-disc-loss=0.000\n",
            "krystal | epoch=3 | time=22:34:57 | speed=0:02:36 | best avg-gen-loss=14.636 (epoch 3) | overtrain countdown: g=50,d=99 | avg-gen-loss=14.636 | avg-disc-loss=0.000\n",
            "krystal | epoch=4 | time=22:37:31 | speed=0:02:33 | best avg-gen-loss=14.197 (epoch 4) | overtrain countdown: g=50,d=98 | avg-gen-loss=14.197 | avg-disc-loss=0.000\n",
            "krystal | epoch=5 | time=22:40:04 | speed=0:02:32 | best avg-gen-loss=13.777 (epoch 5) | overtrain countdown: g=50,d=97 | avg-gen-loss=13.777 | avg-disc-loss=0.000\n",
            "krystal | epoch=6 | time=22:42:37 | speed=0:02:33 | best avg-gen-loss=13.606 (epoch 6) | overtrain countdown: g=50,d=96 | avg-gen-loss=13.606 | avg-disc-loss=0.000\n",
            "krystal | epoch=7 | time=22:45:12 | speed=0:02:34 | best avg-gen-loss=13.238 (epoch 7) | overtrain countdown: g=50,d=95 | avg-gen-loss=13.238 | avg-disc-loss=0.000\n",
            "krystal | epoch=8 | time=22:47:47 | speed=0:02:34 | best avg-gen-loss=12.945 (epoch 8) | overtrain countdown: g=50,d=94 | avg-gen-loss=12.945 | avg-disc-loss=0.000\n",
            "krystal | epoch=9 | time=22:50:21 | speed=0:02:34 | best avg-gen-loss=12.709 (epoch 9) | overtrain countdown: g=50,d=93 | avg-gen-loss=12.709 | avg-disc-loss=0.000\n",
            "krystal | epoch=10 | time=22:52:53 | speed=0:02:32 | best avg-gen-loss=12.550 (epoch 10) | overtrain countdown: g=50,d=92 | avg-gen-loss=12.550 | avg-disc-loss=0.000\n",
            "krystal | epoch=11 | time=22:55:51 | speed=0:02:32 | best avg-gen-loss=12.365 (epoch 11) | overtrain countdown: g=50,d=91 | avg-gen-loss=12.365 | avg-disc-loss=0.000\n",
            "krystal | epoch=12 | time=22:58:28 | speed=0:02:35 | best avg-gen-loss=12.170 (epoch 12) | overtrain countdown: g=50,d=90 | avg-gen-loss=12.170 | avg-disc-loss=0.000\n",
            "krystal | epoch=13 | time=23:01:00 | speed=0:02:32 | best avg-gen-loss=12.031 (epoch 13) | overtrain countdown: g=50,d=89 | avg-gen-loss=12.031 | avg-disc-loss=0.000\n",
            "krystal | epoch=14 | time=23:03:32 | speed=0:02:32 | best avg-gen-loss=11.910 (epoch 14) | overtrain countdown: g=50,d=88 | avg-gen-loss=11.910 | avg-disc-loss=0.000\n",
            "krystal | epoch=15 | time=23:06:05 | speed=0:02:32 | best avg-gen-loss=11.822 (epoch 15) | overtrain countdown: g=50,d=87 | avg-gen-loss=11.822 | avg-disc-loss=0.000\n",
            "krystal | epoch=16 | time=23:08:39 | speed=0:02:34 | best avg-gen-loss=11.783 (epoch 16) | overtrain countdown: g=50,d=86 | avg-gen-loss=11.783 | avg-disc-loss=0.000\n",
            "krystal | epoch=17 | time=23:11:12 | speed=0:02:32 | best avg-gen-loss=11.684 (epoch 17) | overtrain countdown: g=50,d=85 | avg-gen-loss=11.684 | avg-disc-loss=0.000\n",
            "krystal | epoch=18 | time=23:13:45 | speed=0:02:32 | best avg-gen-loss=11.607 (epoch 18) | overtrain countdown: g=50,d=84 | avg-gen-loss=11.607 | avg-disc-loss=0.000\n",
            "krystal | epoch=19 | time=23:16:17 | speed=0:02:32 | best avg-gen-loss=11.497 (epoch 19) | overtrain countdown: g=50,d=83 | avg-gen-loss=11.497 | avg-disc-loss=0.000\n",
            "krystal | epoch=20 | time=23:18:50 | speed=0:02:33 | best avg-gen-loss=11.497 (epoch 19) | overtrain countdown: g=49,d=82 | avg-gen-loss=11.514 | avg-disc-loss=0.000\n",
            "krystal | epoch=21 | time=23:21:39 | speed=0:02:32 | best avg-gen-loss=11.474 (epoch 21) | overtrain countdown: g=50,d=81 | avg-gen-loss=11.474 | avg-disc-loss=0.000\n",
            "krystal | epoch=22 | time=23:24:12 | speed=0:02:32 | best avg-gen-loss=11.427 (epoch 22) | overtrain countdown: g=50,d=80 | avg-gen-loss=11.427 | avg-disc-loss=0.000\n",
            "krystal | epoch=23 | time=23:26:44 | speed=0:02:31 | best avg-gen-loss=11.334 (epoch 23) | overtrain countdown: g=50,d=79 | avg-gen-loss=11.334 | avg-disc-loss=0.000\n",
            "krystal | epoch=24 | time=23:29:17 | speed=0:02:32 | best avg-gen-loss=11.287 (epoch 24) | overtrain countdown: g=50,d=78 | avg-gen-loss=11.287 | avg-disc-loss=0.000\n",
            "krystal | epoch=25 | time=23:31:49 | speed=0:02:31 | best avg-gen-loss=11.244 (epoch 25) | overtrain countdown: g=50,d=77 | avg-gen-loss=11.244 | avg-disc-loss=0.000\n",
            "krystal | epoch=26 | time=23:34:21 | speed=0:02:32 | best avg-gen-loss=11.244 (epoch 25) | overtrain countdown: g=49,d=76 | avg-gen-loss=11.350 | avg-disc-loss=0.000\n",
            "krystal | epoch=27 | time=23:36:53 | speed=0:02:31 | best avg-gen-loss=11.202 (epoch 27) | overtrain countdown: g=50,d=75 | avg-gen-loss=11.202 | avg-disc-loss=0.000\n",
            "krystal | epoch=28 | time=23:39:26 | speed=0:02:33 | best avg-gen-loss=11.192 (epoch 28) | overtrain countdown: g=50,d=74 | avg-gen-loss=11.192 | avg-disc-loss=0.000\n",
            "krystal | epoch=29 | time=23:41:59 | speed=0:02:32 | best avg-gen-loss=11.192 (epoch 28) | overtrain countdown: g=49,d=73 | avg-gen-loss=11.212 | avg-disc-loss=0.000\n",
            "krystal | epoch=30 | time=23:44:32 | speed=0:02:32 | best avg-gen-loss=11.164 (epoch 30) | overtrain countdown: g=50,d=72 | avg-gen-loss=11.164 | avg-disc-loss=0.000\n",
            "krystal | epoch=31 | time=23:47:21 | speed=0:02:33 | best avg-gen-loss=11.120 (epoch 31) | overtrain countdown: g=50,d=71 | avg-gen-loss=11.120 | avg-disc-loss=0.000\n",
            "krystal | epoch=32 | time=23:49:54 | speed=0:02:32 | best avg-gen-loss=11.061 (epoch 32) | overtrain countdown: g=50,d=70 | avg-gen-loss=11.061 | avg-disc-loss=0.000\n",
            "krystal | epoch=33 | time=23:52:27 | speed=0:02:32 | best avg-gen-loss=10.990 (epoch 33) | overtrain countdown: g=50,d=69 | avg-gen-loss=10.990 | avg-disc-loss=0.000\n",
            "krystal | epoch=34 | time=23:54:59 | speed=0:02:32 | best avg-gen-loss=10.990 (epoch 33) | overtrain countdown: g=49,d=68 | avg-gen-loss=11.003 | avg-disc-loss=0.000\n",
            "krystal | epoch=35 | time=23:57:31 | speed=0:02:32 | best avg-gen-loss=10.990 (epoch 33) | overtrain countdown: g=48,d=67 | avg-gen-loss=10.992 | avg-disc-loss=0.000\n",
            "krystal | epoch=36 | time=00:00:04 | speed=0:02:32 | best avg-gen-loss=10.986 (epoch 36) | overtrain countdown: g=50,d=66 | avg-gen-loss=10.986 | avg-disc-loss=0.000\n",
            "krystal | epoch=37 | time=00:02:36 | speed=0:02:32 | best avg-gen-loss=10.871 (epoch 37) | overtrain countdown: g=50,d=65 | avg-gen-loss=10.871 | avg-disc-loss=0.000\n",
            "krystal | epoch=38 | time=00:05:08 | speed=0:02:31 | best avg-gen-loss=10.871 (epoch 37) | overtrain countdown: g=49,d=64 | avg-gen-loss=10.919 | avg-disc-loss=0.000\n",
            "krystal | epoch=39 | time=00:07:41 | speed=0:02:32 | best avg-gen-loss=10.871 (epoch 37) | overtrain countdown: g=48,d=63 | avg-gen-loss=10.895 | avg-disc-loss=0.000\n",
            "krystal | epoch=40 | time=00:10:13 | speed=0:02:32 | best avg-gen-loss=10.871 (epoch 37) | overtrain countdown: g=47,d=62 | avg-gen-loss=10.889 | avg-disc-loss=0.000\n",
            "krystal | epoch=41 | time=00:14:25 | speed=0:02:32 | best avg-gen-loss=10.871 (epoch 37) | overtrain countdown: g=46,d=61 | avg-gen-loss=10.868 | avg-disc-loss=0.000\n",
            "krystal | epoch=42 | time=00:16:58 | speed=0:02:32 | best avg-gen-loss=10.842 (epoch 42) | overtrain countdown: g=50,d=60 | avg-gen-loss=10.842 | avg-disc-loss=0.000\n",
            "krystal | epoch=43 | time=00:19:31 | speed=0:02:32 | best avg-gen-loss=10.787 (epoch 43) | overtrain countdown: g=50,d=59 | avg-gen-loss=10.787 | avg-disc-loss=0.000\n",
            "krystal | epoch=44 | time=00:22:04 | speed=0:02:32 | best avg-gen-loss=10.774 (epoch 44) | overtrain countdown: g=50,d=58 | avg-gen-loss=10.774 | avg-disc-loss=0.000\n",
            "krystal | epoch=45 | time=00:24:37 | speed=0:02:33 | best avg-gen-loss=10.753 (epoch 45) | overtrain countdown: g=50,d=57 | avg-gen-loss=10.753 | avg-disc-loss=0.000\n",
            "krystal | epoch=46 | time=00:27:10 | speed=0:02:32 | best avg-gen-loss=10.753 (epoch 45) | overtrain countdown: g=49,d=56 | avg-gen-loss=10.754 | avg-disc-loss=0.000\n",
            "krystal | epoch=47 | time=00:29:43 | speed=0:02:32 | best avg-gen-loss=10.746 (epoch 47) | overtrain countdown: g=50,d=55 | avg-gen-loss=10.746 | avg-disc-loss=0.000\n",
            "krystal | epoch=48 | time=00:32:16 | speed=0:02:32 | best avg-gen-loss=10.705 (epoch 48) | overtrain countdown: g=50,d=54 | avg-gen-loss=10.705 | avg-disc-loss=0.000\n",
            "krystal | epoch=49 | time=00:34:48 | speed=0:02:32 | best avg-gen-loss=10.644 (epoch 49) | overtrain countdown: g=50,d=53 | avg-gen-loss=10.644 | avg-disc-loss=0.000\n",
            "krystal | epoch=50 | time=00:37:21 | speed=0:02:32 | best avg-gen-loss=10.644 (epoch 49) | overtrain countdown: g=49,d=52 | avg-gen-loss=10.673 | avg-disc-loss=0.000\n",
            "krystal | epoch=51 | time=00:40:30 | speed=0:02:32 | best avg-gen-loss=10.644 (epoch 49) | overtrain countdown: g=48,d=51 | avg-gen-loss=10.655 | avg-disc-loss=0.000\n",
            "krystal | epoch=52 | time=00:43:04 | speed=0:02:33 | best avg-gen-loss=10.632 (epoch 52) | overtrain countdown: g=50,d=50 | avg-gen-loss=10.632 | avg-disc-loss=0.000\n",
            "krystal | epoch=53 | time=00:45:37 | speed=0:02:32 | best avg-gen-loss=10.632 (epoch 52) | overtrain countdown: g=49,d=49 | avg-gen-loss=10.637 | avg-disc-loss=0.000\n",
            "krystal | epoch=54 | time=00:48:10 | speed=0:02:32 | best avg-gen-loss=10.622 (epoch 54) | overtrain countdown: g=50,d=48 | avg-gen-loss=10.622 | avg-disc-loss=0.000\n",
            "krystal | epoch=55 | time=00:50:43 | speed=0:02:32 | best avg-gen-loss=10.588 (epoch 55) | overtrain countdown: g=50,d=47 | avg-gen-loss=10.588 | avg-disc-loss=0.000\n",
            "krystal | epoch=56 | time=00:53:18 | speed=0:02:35 | best avg-gen-loss=10.573 (epoch 56) | overtrain countdown: g=50,d=46 | avg-gen-loss=10.573 | avg-disc-loss=0.000\n",
            "krystal | epoch=57 | time=00:55:52 | speed=0:02:33 | best avg-gen-loss=10.528 (epoch 57) | overtrain countdown: g=50,d=45 | avg-gen-loss=10.528 | avg-disc-loss=0.000\n",
            "krystal | epoch=58 | time=00:58:24 | speed=0:02:32 | best avg-gen-loss=10.528 (epoch 57) | overtrain countdown: g=49,d=44 | avg-gen-loss=10.537 | avg-disc-loss=0.000\n",
            "krystal | epoch=59 | time=01:00:57 | speed=0:02:32 | best avg-gen-loss=10.518 (epoch 59) | overtrain countdown: g=50,d=43 | avg-gen-loss=10.518 | avg-disc-loss=0.000\n",
            "krystal | epoch=60 | time=01:03:30 | speed=0:02:32 | best avg-gen-loss=10.505 (epoch 60) | overtrain countdown: g=50,d=42 | avg-gen-loss=10.505 | avg-disc-loss=0.000\n",
            "krystal | epoch=61 | time=01:06:38 | speed=0:02:33 | best avg-gen-loss=10.505 (epoch 60) | overtrain countdown: g=49,d=41 | avg-gen-loss=10.531 | avg-disc-loss=0.000\n",
            "krystal | epoch=62 | time=01:09:11 | speed=0:02:33 | best avg-gen-loss=10.470 (epoch 62) | overtrain countdown: g=50,d=40 | avg-gen-loss=10.470 | avg-disc-loss=0.000\n",
            "krystal | epoch=63 | time=01:11:44 | speed=0:02:32 | best avg-gen-loss=10.470 (epoch 62) | overtrain countdown: g=49,d=39 | avg-gen-loss=10.468 | avg-disc-loss=0.000\n",
            "krystal | epoch=64 | time=01:14:16 | speed=0:02:32 | best avg-gen-loss=10.470 (epoch 62) | overtrain countdown: g=48,d=38 | avg-gen-loss=10.489 | avg-disc-loss=0.000\n",
            "krystal | epoch=65 | time=01:16:49 | speed=0:02:32 | best avg-gen-loss=10.439 (epoch 65) | overtrain countdown: g=50,d=37 | avg-gen-loss=10.439 | avg-disc-loss=0.000\n",
            "krystal | epoch=66 | time=01:19:23 | speed=0:02:33 | best avg-gen-loss=10.439 (epoch 65) | overtrain countdown: g=49,d=36 | avg-gen-loss=10.439 | avg-disc-loss=0.000\n",
            "krystal | epoch=67 | time=01:21:56 | speed=0:02:32 | best avg-gen-loss=10.422 (epoch 67) | overtrain countdown: g=50,d=35 | avg-gen-loss=10.422 | avg-disc-loss=0.000\n",
            "krystal | epoch=68 | time=01:24:29 | speed=0:02:32 | best avg-gen-loss=10.407 (epoch 68) | overtrain countdown: g=50,d=34 | avg-gen-loss=10.407 | avg-disc-loss=0.000\n",
            "krystal | epoch=69 | time=01:27:01 | speed=0:02:32 | best avg-gen-loss=10.336 (epoch 69) | overtrain countdown: g=50,d=33 | avg-gen-loss=10.336 | avg-disc-loss=0.000\n",
            "krystal | epoch=70 | time=01:29:34 | speed=0:02:32 | best avg-gen-loss=10.336 (epoch 69) | overtrain countdown: g=49,d=32 | avg-gen-loss=10.416 | avg-disc-loss=0.000\n",
            "krystal | epoch=71 | time=01:34:02 | speed=0:02:35 | best avg-gen-loss=10.336 (epoch 69) | overtrain countdown: g=48,d=31 | avg-gen-loss=10.341 | avg-disc-loss=0.000\n",
            "krystal | epoch=72 | time=01:36:34 | speed=0:02:32 | best avg-gen-loss=10.336 (epoch 69) | overtrain countdown: g=47,d=30 | avg-gen-loss=10.371 | avg-disc-loss=0.000\n",
            "krystal | epoch=73 | time=01:39:07 | speed=0:02:32 | best avg-gen-loss=10.336 (epoch 69) | overtrain countdown: g=46,d=29 | avg-gen-loss=10.423 | avg-disc-loss=0.000\n",
            "krystal | epoch=74 | time=01:41:39 | speed=0:02:32 | best avg-gen-loss=10.315 (epoch 74) | overtrain countdown: g=50,d=28 | avg-gen-loss=10.315 | avg-disc-loss=0.000\n",
            "krystal | epoch=75 | time=01:44:11 | speed=0:02:32 | best avg-gen-loss=10.315 (epoch 74) | overtrain countdown: g=49,d=27 | avg-gen-loss=10.340 | avg-disc-loss=0.000\n",
            "krystal | epoch=76 | time=01:46:44 | speed=0:02:32 | best avg-gen-loss=10.315 (epoch 74) | overtrain countdown: g=48,d=26 | avg-gen-loss=10.339 | avg-disc-loss=0.000\n",
            "krystal | epoch=77 | time=01:49:17 | speed=0:02:32 | best avg-gen-loss=10.315 (epoch 74) | overtrain countdown: g=47,d=25 | avg-gen-loss=10.313 | avg-disc-loss=0.000\n",
            "krystal | epoch=78 | time=01:51:49 | speed=0:02:32 | best avg-gen-loss=10.315 (epoch 74) | overtrain countdown: g=46,d=24 | avg-gen-loss=10.322 | avg-disc-loss=0.000\n",
            "krystal | epoch=79 | time=01:54:21 | speed=0:02:32 | best avg-gen-loss=10.286 (epoch 79) | overtrain countdown: g=50,d=23 | avg-gen-loss=10.286 | avg-disc-loss=0.000\n",
            "krystal | epoch=80 | time=01:56:54 | speed=0:02:32 | best avg-gen-loss=10.178 (epoch 80) | overtrain countdown: g=50,d=22 | avg-gen-loss=10.178 | avg-disc-loss=0.000\n",
            "krystal | epoch=81 | time=02:00:20 | speed=0:02:32 | best avg-gen-loss=10.178 (epoch 80) | overtrain countdown: g=49,d=21 | avg-gen-loss=10.187 | avg-disc-loss=0.000\n",
            "krystal | epoch=82 | time=02:02:52 | speed=0:02:32 | best avg-gen-loss=10.178 (epoch 80) | overtrain countdown: g=48,d=20 | avg-gen-loss=10.179 | avg-disc-loss=0.000\n",
            "krystal | epoch=83 | time=02:05:24 | speed=0:02:32 | best avg-gen-loss=10.119 (epoch 83) | overtrain countdown: g=50,d=19 | avg-gen-loss=10.119 | avg-disc-loss=0.000\n",
            "krystal | epoch=84 | time=02:07:57 | speed=0:02:32 | best avg-gen-loss=10.119 (epoch 83) | overtrain countdown: g=49,d=18 | avg-gen-loss=10.137 | avg-disc-loss=0.000\n",
            "krystal | epoch=85 | time=02:10:29 | speed=0:02:31 | best avg-gen-loss=10.119 (epoch 83) | overtrain countdown: g=48,d=17 | avg-gen-loss=10.136 | avg-disc-loss=0.000\n",
            "krystal | epoch=86 | time=02:13:01 | speed=0:02:31 | best avg-gen-loss=10.119 (epoch 83) | overtrain countdown: g=47,d=16 | avg-gen-loss=10.142 | avg-disc-loss=0.000\n",
            "krystal | epoch=87 | time=02:15:33 | speed=0:02:32 | best avg-gen-loss=10.119 (epoch 83) | overtrain countdown: g=46,d=15 | avg-gen-loss=10.204 | avg-disc-loss=0.000\n",
            "krystal | epoch=88 | time=02:18:07 | speed=0:02:33 | best avg-gen-loss=10.119 (epoch 83) | overtrain countdown: g=45,d=14 | avg-gen-loss=10.280 | avg-disc-loss=0.001\n",
            "krystal | epoch=89 | time=02:20:39 | speed=0:02:32 | best avg-gen-loss=10.119 (epoch 83) | overtrain countdown: g=44,d=13 | avg-gen-loss=10.298 | avg-disc-loss=0.005\n",
            "krystal | epoch=90 | time=02:23:12 | speed=0:02:32 | best avg-gen-loss=10.119 (epoch 83) | overtrain countdown: g=43,d=12 | avg-gen-loss=10.404 | avg-disc-loss=0.011\n",
            "krystal | epoch=91 | time=02:27:29 | speed=0:02:33 | best avg-gen-loss=10.119 (epoch 83) | overtrain countdown: g=42,d=11 | avg-gen-loss=10.436 | avg-disc-loss=0.017\n",
            "krystal | epoch=92 | time=02:30:02 | speed=0:02:32 | best avg-gen-loss=10.119 (epoch 83) | overtrain countdown: g=41,d=10 | avg-gen-loss=10.390 | avg-disc-loss=0.038\n",
            "krystal | epoch=93 | time=02:32:34 | speed=0:02:32 | best avg-gen-loss=9.193 (epoch 93) | overtrain countdown: g=50,d=9 | avg-gen-loss=9.193 | avg-disc-loss=0.277\n",
            "krystal | epoch=94 | time=02:35:06 | speed=0:02:32 | best avg-gen-loss=8.432 (epoch 94) | overtrain countdown: g=50,d=8 | avg-gen-loss=8.432 | avg-disc-loss=0.398\n",
            "krystal | epoch=95 | time=02:37:39 | speed=0:02:32 | best avg-gen-loss=8.342 (epoch 95) | overtrain countdown: g=50,d=7 | avg-gen-loss=8.342 | avg-disc-loss=0.387\n",
            "krystal | epoch=96 | time=02:40:12 | speed=0:02:32 | best avg-gen-loss=8.240 (epoch 96) | overtrain countdown: g=50,d=6 | avg-gen-loss=8.240 | avg-disc-loss=0.384\n",
            "krystal | epoch=97 | time=02:42:45 | speed=0:02:33 | best avg-gen-loss=7.589 (epoch 97) | overtrain countdown: g=50,d=5 | avg-gen-loss=7.589 | avg-disc-loss=0.482\n",
            "krystal | epoch=98 | time=02:45:18 | speed=0:02:32 | best avg-gen-loss=7.589 (epoch 97) | overtrain countdown: g=49,d=4 | avg-gen-loss=7.714 | avg-disc-loss=0.467\n",
            "krystal | epoch=99 | time=02:47:51 | speed=0:02:32 | best avg-gen-loss=7.535 (epoch 99) | overtrain countdown: g=50,d=3 | avg-gen-loss=7.535 | avg-disc-loss=0.458\n",
            "krystal | epoch=100 | time=02:50:24 | speed=0:02:32 | best avg-gen-loss=7.212 (epoch 100) | overtrain countdown: g=50,d=2 | avg-gen-loss=7.212 | avg-disc-loss=0.479\n",
            "krystal | epoch=101 | time=02:54:47 | speed=0:02:32 | best avg-gen-loss=7.203 (epoch 101) | overtrain countdown: g=50,d=1 | avg-gen-loss=7.203 | avg-disc-loss=0.478\n",
            "krystal | epoch=102 | time=02:57:20 | speed=0:02:32 | best avg-gen-loss=7.080 (epoch 102) | overtrain countdown: g=50,d=0 | avg-gen-loss=7.080 | avg-disc-loss=0.488\n",
            "Overtraining detected at epoch 102 with average generator loss 7.080 and discriminator loss 0.488\n",
            "\u001b[1m[\u001b[0m~\u001b[1m]\u001b[0m Retrieving song\u001b[33m...\u001b[0m\n",
            "\u001b[1m[\u001b[0m~\u001b[1m]\u001b[0m Separating vocals from instrumentals\u001b[33m...\u001b[0m\n",
            "4.38kiB [00:00, 10.3MiB/s]      \n",
            "15.4kiB [00:00, 43.4MiB/s]      \n",
            "2025-09-07 03:48:42 - WARNING - audio_separator.separator.separator - Model converted from onnx to pytorch due to segment size not matching dim_t, processing may be slower.\n",
            "100% 28/28 [00:37<00:00,  1.36s/it]\n",
            "100% 22/22 [00:04<00:00,  4.62it/s]\n",
            "\u001b[1m[\u001b[0m~\u001b[1m]\u001b[0m Separating main vocals from backup vocals\u001b[33m...\u001b[0m\n",
            "2025-09-07 03:49:29 - WARNING - audio_separator.separator.separator - Model converted from onnx to pytorch due to segment size not matching dim_t, processing may be slower.\n",
            "100% 28/28 [00:26<00:00,  1.06it/s]\n",
            "100% 22/22 [00:05<00:00,  3.94it/s]\n",
            "\u001b[1m[\u001b[0m~\u001b[1m]\u001b[0m De-reverbing vocals\u001b[33m...\u001b[0m\n",
            "2025-09-07 03:50:03 - WARNING - audio_separator.separator.separator - Model converted from onnx to pytorch due to segment size not matching dim_t, processing may be slower.\n",
            "100% 55/55 [00:33<00:00,  1.63it/s]\n",
            "100% 42/42 [00:04<00:00, 10.31it/s]\n",
            "\u001b[1m[\u001b[0m~\u001b[1m]\u001b[0m Converting vocals\u001b[33m...\u001b[0m\n",
            "\u001b[1m[\u001b[0m~\u001b[1m]\u001b[0m Post-processing vocals\u001b[33m...\u001b[0m\n",
            "\u001b[1m[\u001b[0m~\u001b[1m]\u001b[0m Pitch-shifting instrumentals\u001b[33m...\u001b[0m\n",
            "\u001b[1m[\u001b[0m~\u001b[1m]\u001b[0m Pitch-shifting backup vocals\u001b[33m...\u001b[0m\n",
            "\u001b[1m[\u001b[0m~\u001b[1m]\u001b[0m Downloading voice model \u001b[33m...\u001b[0m\n",
            "Downloading files: 222MiB [00:08, 45.2MiB/s]\u001b[1m[\u001b[0m~\u001b[1m]\u001b[0m Extracting zip file\u001b[33m...\u001b[0m\n",
            "Downloading files: 614MiB [00:31, 54.1MiB/s]Traceback (most recent call last):\n",
            "  File \"/content/HRVC/src/ultimate_rvc/web/common.py\", line 70, in _wrapped_fn\n",
            "    res = fn(*args, **kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/HRVC/src/ultimate_rvc/core/manage/models.py\", line 367, in download_voice_model\n",
            "    _extract_voice_model(zip_name, extraction_path, remove_zip=True)\n",
            "  File \"/content/HRVC/src/ultimate_rvc/core/manage/models.py\", line 313, in _extract_voice_model\n",
            "    raise NotFoundError(\n",
            "ultimate_rvc.core.exceptions.NotFoundError: Model file not found in extracted zip file\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/HRVC/.venv/lib/python3.12/site-packages/gradio/queueing.py\", line 625, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/HRVC/.venv/lib/python3.12/site-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/HRVC/.venv/lib/python3.12/site-packages/gradio/blocks.py\", line 2136, in process_api\n",
            "    result = await self.call_function(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/HRVC/.venv/lib/python3.12/site-packages/gradio/blocks.py\", line 1662, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/HRVC/.venv/lib/python3.12/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
            "    return await get_async_backend().run_sync_in_worker_thread(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/HRVC/.venv/lib/python3.12/site-packages/anyio/_backends/_asyncio.py\", line 2476, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/content/HRVC/.venv/lib/python3.12/site-packages/anyio/_backends/_asyncio.py\", line 967, in run\n",
            "    result = context.run(func, *args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/HRVC/.venv/lib/python3.12/site-packages/gradio/utils.py\", line 883, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/HRVC/src/ultimate_rvc/web/common.py\", line 77, in _wrapped_fn\n",
            "    raise gr.Error(str(e)) from e\n",
            "gradio.exceptions.Error: 'Model file not found in extracted zip file'\n",
            "Downloading files: 1.31GiB [00:47, 27.8MiB/s]\n",
            "\u001b[1m[\u001b[0m~\u001b[1m]\u001b[0m Retrieving song\u001b[33m...\u001b[0m\n",
            "\u001b[1m[\u001b[0m~\u001b[1m]\u001b[0m Separating vocals from instrumentals\u001b[33m...\u001b[0m\n",
            "2025-09-07 21:00:41 - WARNING - audio_separator.separator.separator - Model converted from onnx to pytorch due to segment size not matching dim_t, processing may be slower.\n",
            "100% 31/31 [00:40<00:00,  1.31s/it]\n",
            "100% 24/24 [00:06<00:00,  3.99it/s]\n",
            "\u001b[1m[\u001b[0m~\u001b[1m]\u001b[0m Separating main vocals from backup vocals\u001b[33m...\u001b[0m\n",
            "2025-09-07 21:01:31 - WARNING - audio_separator.separator.separator - Model converted from onnx to pytorch due to segment size not matching dim_t, processing may be slower.\n",
            "100% 31/31 [00:28<00:00,  1.07it/s]\n",
            "100% 24/24 [00:06<00:00,  4.00it/s]\n",
            "\u001b[1m[\u001b[0m~\u001b[1m]\u001b[0m De-reverbing vocals\u001b[33m...\u001b[0m\n",
            "2025-09-07 21:02:09 - WARNING - audio_separator.separator.separator - Model converted from onnx to pytorch due to segment size not matching dim_t, processing may be slower.\n",
            "100% 59/59 [00:36<00:00,  1.62it/s]\n",
            "100% 45/45 [00:04<00:00, 10.03it/s]\n",
            "\u001b[1m[\u001b[0m~\u001b[1m]\u001b[0m Converting vocals\u001b[33m...\u001b[0m\n",
            "\u001b[1m[\u001b[0m~\u001b[1m]\u001b[0m Post-processing vocals\u001b[33m...\u001b[0m\n",
            "\u001b[1m[\u001b[0m~\u001b[1m]\u001b[0m Pitch-shifting instrumentals\u001b[33m...\u001b[0m\n",
            "\u001b[1m[\u001b[0m~\u001b[1m]\u001b[0m Pitch-shifting backup vocals\u001b[33m...\u001b[0m\n",
            "\u001b[1m[\u001b[0m~\u001b[1m]\u001b[0m Retrieving song\u001b[33m...\u001b[0m\n",
            "\u001b[1m[\u001b[0m~\u001b[1m]\u001b[0m Separating vocals from instrumentals\u001b[33m...\u001b[0m\n",
            "\u001b[1m[\u001b[0m~\u001b[1m]\u001b[0m Separating main vocals from backup vocals\u001b[33m...\u001b[0m\n",
            "\u001b[1m[\u001b[0m~\u001b[1m]\u001b[0m De-reverbing vocals\u001b[33m...\u001b[0m\n",
            "\u001b[1m[\u001b[0m~\u001b[1m]\u001b[0m Converting vocals\u001b[33m...\u001b[0m\n",
            "\u001b[1m[\u001b[0m~\u001b[1m]\u001b[0m Post-processing vocals\u001b[33m...\u001b[0m\n",
            "\u001b[1m[\u001b[0m~\u001b[1m]\u001b[0m Pitch-shifting instrumentals\u001b[33m...\u001b[0m\n",
            "\u001b[1m[\u001b[0m~\u001b[1m]\u001b[0m Pitch-shifting backup vocals\u001b[33m...\u001b[0m\n",
            "100% 53/53 [01:24<00:00,  1.60s/it]\n",
            "\u001b[1m[\u001b[0m~\u001b[1m]\u001b[0m Extracting pitch features\u001b[33m...\u001b[0m\n",
            "100% 53/53 [00:13<00:00,  3.80it/s]\n",
            "\u001b[1m[\u001b[0m~\u001b[1m]\u001b[0m Extracting audio embeddings\u001b[33m...\u001b[0m\n",
            "100% 53/53 [00:16<00:00,  3.28it/s]\n",
            "/content/HRVC/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "2025-09-07 21:36:37 - ERROR - ultimate_rvc.rvc.train.train - Not enough data in the training set. Perhaps you forgot to slice the audio files in preprocess?\n",
            "[rank0]:[W907 21:36:38.681623321 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n",
            "2025-09-07 21:36:38 - WARNING - ultimate_rvc.rvc.train.train - Process running on device 0 exited with code 1.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/HRVC/src/ultimate_rvc/web/common.py\", line 70, in _wrapped_fn\n",
            "    res = fn(*args, **kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/HRVC/src/ultimate_rvc/core/train/train.py\", line 299, in run_training\n",
            "    train_main(\n",
            "  File \"/content/HRVC/src/ultimate_rvc/rvc/train/train.py\", line 269, in main\n",
            "    start()\n",
            "  File \"/content/HRVC/src/ultimate_rvc/rvc/train/train.py\", line 254, in start\n",
            "    raise RuntimeError(err_msg)\n",
            "RuntimeError: One or more training processes failed. See the logs or console for details.\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/HRVC/.venv/lib/python3.12/site-packages/gradio/queueing.py\", line 625, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/HRVC/.venv/lib/python3.12/site-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/HRVC/.venv/lib/python3.12/site-packages/gradio/blocks.py\", line 2136, in process_api\n",
            "    result = await self.call_function(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/HRVC/.venv/lib/python3.12/site-packages/gradio/blocks.py\", line 1662, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/HRVC/.venv/lib/python3.12/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
            "    return await get_async_backend().run_sync_in_worker_thread(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/HRVC/.venv/lib/python3.12/site-packages/anyio/_backends/_asyncio.py\", line 2476, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/content/HRVC/.venv/lib/python3.12/site-packages/anyio/_backends/_asyncio.py\", line 967, in run\n",
            "    result = context.run(func, *args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/HRVC/.venv/lib/python3.12/site-packages/gradio/utils.py\", line 883, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/HRVC/src/ultimate_rvc/web/common.py\", line 77, in _wrapped_fn\n",
            "    raise gr.Error(str(e)) from e\n",
            "gradio.exceptions.Error: 'One or more training processes failed. See the logs or console for details.'\n",
            "/content/HRVC/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "2025-09-07 21:38:46 - ERROR - ultimate_rvc.rvc.train.train - Not enough data in the training set. Perhaps you forgot to slice the audio files in preprocess?\n",
            "[rank0]:[W907 21:38:47.882331569 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n",
            "2025-09-07 21:38:47 - WARNING - ultimate_rvc.rvc.train.train - Process running on device 0 exited with code 1.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/HRVC/src/ultimate_rvc/web/common.py\", line 70, in _wrapped_fn\n",
            "    res = fn(*args, **kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/HRVC/src/ultimate_rvc/core/train/train.py\", line 299, in run_training\n",
            "    train_main(\n",
            "  File \"/content/HRVC/src/ultimate_rvc/rvc/train/train.py\", line 269, in main\n",
            "    start()\n",
            "  File \"/content/HRVC/src/ultimate_rvc/rvc/train/train.py\", line 254, in start\n",
            "    raise RuntimeError(err_msg)\n",
            "RuntimeError: One or more training processes failed. See the logs or console for details.\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/HRVC/.venv/lib/python3.12/site-packages/gradio/queueing.py\", line 625, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/HRVC/.venv/lib/python3.12/site-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/HRVC/.venv/lib/python3.12/site-packages/gradio/blocks.py\", line 2136, in process_api\n",
            "    result = await self.call_function(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/HRVC/.venv/lib/python3.12/site-packages/gradio/blocks.py\", line 1662, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/HRVC/.venv/lib/python3.12/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
            "    return await get_async_backend().run_sync_in_worker_thread(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/HRVC/.venv/lib/python3.12/site-packages/anyio/_backends/_asyncio.py\", line 2476, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/content/HRVC/.venv/lib/python3.12/site-packages/anyio/_backends/_asyncio.py\", line 967, in run\n",
            "    result = context.run(func, *args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/HRVC/.venv/lib/python3.12/site-packages/gradio/utils.py\", line 883, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/HRVC/src/ultimate_rvc/web/common.py\", line 77, in _wrapped_fn\n",
            "    raise gr.Error(str(e)) from e\n",
            "gradio.exceptions.Error: 'One or more training processes failed. See the logs or console for details.'\n"
          ]
        }
      ],
      "source": [
        "# @title 3: Run Ultimate RVC\n",
        "# @markdown  #### Choose a sharing method:\n",
        "\n",
        "method = \"ngrok\"  # @param [\"gradio\",  \"ngrok\", \"cloudflared\",\"localtunnel\"]\n",
        "ngrok_token = \"1bmuAjm2E2Y6vqixmAzgc2iwANN_2k6cWmvqJZ3GEP4rMkqeV\"  # @param {type:\"string\"}\n",
        "runpice = codecs.decode(\"./fep/hygvzngr_eip/jro/znva.cl\", \"rot_13\")\n",
        "\n",
        "if method == \"gradio\":\n",
        "    !uv run $prerelease $runpice --share\n",
        "elif method == \"ngrok\":\n",
        "    try:\n",
        "        ngrok.set_auth_token(ngrok_token)\n",
        "        ngrok.kill()\n",
        "        tunnel = ngrok.connect(6969)\n",
        "        print(f\"Ngrok URL: {tunnel.public_url}\")\n",
        "        !uv run $prerelease $runpice --listen-port 6969\n",
        "    except Exception as e:  # noqa: BLE001\n",
        "        print(f\"Error starting ngrok: {e}\")\n",
        "elif method == \"cloudflared\":\n",
        "    !curl -LO https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
        "    !dpkg -i cloudflared-linux-amd64.deb\n",
        "    clear_output()\n",
        "    !rm -rf nohup.out\n",
        "    !nohup cloudflared tunnel --url localhost:6969 &\n",
        "    clear_output()\n",
        "    time.sleep(10)\n",
        "    cloudflare_url = !grep -oE \"https://[a-zA-Z0-9.-]+\\.trycloudflare\\.com\" nohup.out\n",
        "    print(f\"URVC Public URL: {cloudflare_url}\")\n",
        "    !uv run $prerelease $runpice --listen-port 6969\n",
        "elif method == \"localtunnel\":\n",
        "    !npm install -g localtunnel &>/dev/null\n",
        "    Path(\"url.txt\").open(\"w\", encoding=\"utf-8\").close()\n",
        "    !lt --port 6969 >> url.txt 2>&1 &\n",
        "    time.sleep(2)\n",
        "    endpoint_ip = (\n",
        "        request.urlopen(\"https://ipv4.icanhazip.com\").read().decode(\"utf8\").strip(\"\\n\")\n",
        "    )\n",
        "    tunnel_url = (\n",
        "        Path(\"url.txt\").read_text(encoding=\"utf-8\").replace(\"your url is: \", \"\")\n",
        "    )\n",
        "    print(f\"Share Link: {tunnel_url}\")\n",
        "    password_endpoint_widget = widgets.Text(\n",
        "        value=endpoint_ip,\n",
        "        description=\"Password IP:\",\n",
        "        disabled=True,\n",
        "    )\n",
        "    i_display(password_endpoint_widget)\n",
        "    !uv run $prerelease $runpice --listen-port 6969"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}